{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3dd957d",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "d3dd957d"
      },
      "source": [
        "# Inference Optimizations\n",
        "Note: used google collab for GPU because of time constraint. \\\n",
        "In real pipeline this would be done after training on GPU instance."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-process Data"
      ],
      "metadata": {
        "id": "kj8Izgcb689h"
      },
      "id": "kj8Izgcb689h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Move to the correct path\n",
        "!mkdir -p /content/.kaggle\n",
        "!cp kaggle.json /content/.kaggle/\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "\n",
        "# Set the environment variable so the API knows where to look\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/.kaggle\"\n",
        "\n",
        "# Test\n",
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "2YjN67g88YE-",
        "outputId": "36544560-e73c-4de5-dcbf-86b10097f482"
      },
      "id": "2YjN67g88YE-",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2dd81ed8-bc1d-4de1-84d5-278a6861f758\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2dd81ed8-bc1d-4de1-84d5-278a6861f758\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "ref                                                          title                                                      size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "-----------------------------------------------------------  --------------------------------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
            "jayaantanaath/student-habits-vs-academic-performance         Student Habits vs Academic Performance                    19512  2025-04-12 10:49:08.663000          23311        401  1.0              \n",
            "adilshamim8/cost-of-international-education                  Cost of International Education                           18950  2025-05-07 15:41:53.213000           4630         78  1.0              \n",
            "adilshamim8/social-media-addiction-vs-relationships          Students' Social Media Addiction                           7851  2025-05-10 14:38:02.713000           2137         34  1.0              \n",
            "fatemehmohammadinia/heart-attack-dataset-tarik-a-rashid      Heart Attack Dataset                                      16250  2025-04-30 21:58:22.740000           4561         79  1.0              \n",
            "ivankmk/thousand-ml-jobs-in-usa                              Machine Learning Job Postings in the US                 1682058  2025-04-20 16:11:59.347000           4449         99  1.0              \n",
            "mahdimashayekhi/fake-news-detection-dataset                  Fake News Detection Dataset                            11735585  2025-04-27 14:52:10.607000           1964         26  1.0              \n",
            "michaelmatta0/global-development-indicators-2000-2020        Global Development Full Analysis (2000-2020)            1311638  2025-05-11 16:57:19.013000            787         24  1.0              \n",
            "aryan208/financial-transactions-dataset-for-fraud-detection  Financial Transactions Dataset for Fraud Detection    290256858  2025-05-02 09:12:28.203000           1224         29  1.0              \n",
            "umeradnaan/daily-social-media-active-users                   Daily Social Media Active Users                          126814  2025-05-05 02:11:50.873000           1696         23  1.0              \n",
            "khushikyad001/impact-of-screen-time-on-mental-health         Impact of Screen Time on Mental Health                    64873  2025-04-20 18:01:47.570000           2757         43  1.0              \n",
            "dnkumars/cryptocurrency-transaction-analytics-btc-and-eth    Cryptocurrency Transaction Analytics: BTC & ETH         5167978  2025-05-11 15:16:52.107000            405         30  1.0              \n",
            "madhuraatmarambhagat/crop-recommendation-dataset             Crop Recommendation Dataset                               65234  2025-05-08 17:02:09.397000            787         27  1.0              \n",
            "zahidmughal2343/global-cancer-patients-2015-2024             global_cancer_patients_2015_2024                        1261049  2025-04-14 00:05:23.367000           5231         65  1.0              \n",
            "razanaqvi14/real-and-fake-news                               Real & Fake News                                       42975911  2025-04-28 19:46:53.073000           1065         22  1.0              \n",
            "adilshamim8/greenhouse-plant-growth-metrics                  Greenhouse Plant Growth                                 3041046  2025-04-19 07:33:57.787000           1800         28  1.0              \n",
            "wikimedia-foundation/wikipedia-structured-contents           Wikipedia Structured Contents                       25121685657  2025-04-11 07:11:03.397000           2237        287  0.8125           \n",
            "glowstudygram/spotify-songs-and-artists-dataset              Spotify Songs and Artists Dataset | Audio Features        68415  2025-04-27 12:38:36.850000           1867         31  0.8235294        \n",
            "nikolasgegenava/sneakers-classification                      Popular Sneakers Classification                        17981294  2025-05-01 12:00:45.517000           1604         42  1.0              \n",
            "palvinder2006/ola-bike-ride-request                          Ola Bike Ride Request                                    174975  2025-04-28 03:55:33.860000           1098         28  1.0              \n",
            "adilshamim8/predict-students-dropout-and-academic-success    Student Dropout & Success Prediction Dataset             106181  2025-04-23 06:34:06.433000           2521         39  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "\n",
        "# os.environ[\"KAGGLE_CONFIG_DIR\"] = os.path.abspath(\".kaggle\") # Use local .kaggle directory\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi"
      ],
      "metadata": {
        "id": "brjGUd9A74BN"
      },
      "id": "brjGUd9A74BN",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_jigsaw(kaggle_dir):\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    # Download competition data\n",
        "    api.competition_download_files(\n",
        "        \"jigsaw-unintended-bias-in-toxicity-classification\",\n",
        "        path=kaggle_dir\n",
        "    )\n",
        "\n",
        "    # Unzip\n",
        "    zip_path = os.path.join(kaggle_dir, \"jigsaw-unintended-bias-in-toxicity-classification.zip\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(kaggle_dir)\n",
        "\n",
        "    print(\"Downloaded and extracted Jigsaw dataset.\")\n",
        "\n",
        "\n",
        "def preprocess(kaggle_dir, output_dir, split_ratio=0.2):\n",
        "    # Create output directory if missing\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Ensure input file exists, create parent dir if needed (just in case)\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "    input_path = os.path.join(kaggle_dir, \"train.csv\")\n",
        "    if not os.path.exists(input_path):\n",
        "        raise FileNotFoundError(f\"train.csv not found in {kaggle_dir}\")\n",
        "\n",
        "    df = pd.read_csv(input_path).dropna(subset=[\"comment_text\"])\n",
        "\n",
        "    # Keep only the needed columns\n",
        "    df = df[[\"comment_text\", \"target\"]]\n",
        "\n",
        "    # Binarize target (optional: uncomment if needed)\n",
        "    # df[\"target\"] = (df[\"target\"] >= 0.5).astype(int)\n",
        "\n",
        "    # Split\n",
        "    train_df, val_df = train_test_split(df, test_size=split_ratio, random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
        "    val_df.to_csv(os.path.join(output_dir, \"val.csv\"), index=False)\n",
        "\n",
        "    print(f\"Saved {len(train_df)} training and {len(val_df)} validation samples to {output_dir}\")"
      ],
      "metadata": {
        "id": "wlF8J4Je72OJ"
      },
      "id": "wlF8J4Je72OJ",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_dir = \"data/jigsaw/raw/\"\n",
        "output_dir = \"data/jigsaw/processed/\"\n",
        "val_split = 0.2\n",
        "\n",
        "download_jigsaw(kaggle_dir)\n",
        "preprocess(kaggle_dir, output_dir, val_split)"
      ],
      "metadata": {
        "id": "s83yLZkY784G"
      },
      "id": "s83yLZkY784G",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "W6WLW_2G7z2B"
      },
      "id": "W6WLW_2G7z2B"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
      ],
      "metadata": {
        "id": "zGBzK-M26-VF"
      },
      "id": "zGBzK-M26-VF",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"initial_epochs\": 2,\n",
        "    \"total_epochs\": 1,\n",
        "    \"patience\": 2,\n",
        "    \"batch_size\": 128,\n",
        "    \"lr\": 2e-5,\n",
        "    \"fine_tune_lr\": 1e-5,\n",
        "    \"max_len\": 128,\n",
        "    \"dropout_probability\": 0.3,\n",
        "    \"model_name\": \"distilbert-base-uncased\"\n",
        "}"
      ],
      "metadata": {
        "id": "68nz89tK6Kmo"
      },
      "id": "68nz89tK6Kmo",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Dataset\n",
        "# ---------------------------\n",
        "class JigsawDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.texts = df[\"comment_text\"].tolist()\n",
        "        self.labels = (df[\"target\"] >= 0.5).astype(int).tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "KSfh49tW6unS"
      },
      "id": "KSfh49tW6unS",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Training + Evaluation Functions\n",
        "# ---------------------------\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    num_batches = int(0.01 * len(loader)) # Doing part of the training because my part is inference and monitoring\n",
        "    print(f\"Training for {num_batches} batches\")\n",
        "\n",
        "    for i, batch in enumerate(tqdm(loader, desc=\"Training\", leave=False)):\n",
        "        if i >= num_batches:\n",
        "            break\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.logits.argmax(dim=1)\n",
        "        correct += (preds == batch[\"labels\"]).sum().item()\n",
        "        total += batch[\"labels\"].size(0)\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_acc = correct / total\n",
        "    print(f\"Partial Epoch Summary - Avg Loss: {avg_loss:.4f}, Avg Accuracy: {avg_acc:.4f}\\n\")\n",
        "\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            correct += (preds == batch[\"labels\"]).sum().item()\n",
        "            total += batch[\"labels\"].size(0)\n",
        "\n",
        "    return total_loss / len(loader), correct / total"
      ],
      "metadata": {
        "id": "QJrmvVAy6ys6"
      },
      "id": "QJrmvVAy6ys6",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Main Training Pipeline\n",
        "# ---------------------------\n",
        "def main(args):\n",
        "    # made to run in command line originally\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # parser.add_argument(\"--data-dir\", type=str, required=True, help=\"Directory with train.csv and val.csv\")\n",
        "    # parser.add_argument(\"--save-path\", type=str, required=True, help=\"Path to save the trained model\")\n",
        "    # parser.add_argument(\"--dry-run\", action=\"store_true\", help=\"Run a quick test on a small sample\")\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    os.makedirs(os.path.dirname(args.save_path), exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(config[\"model_name\"])\n",
        "    train_df = pd.read_csv(os.path.join(args.data_dir, \"train.csv\"))\n",
        "    if args.dry_run:\n",
        "        train_df = train_df.sample(n=32, random_state=42)\n",
        "    val_df = pd.read_csv(os.path.join(args.data_dir, \"val.csv\"))\n",
        "    if args.dry_run:\n",
        "        val_df = val_df.sample(n=32, random_state=42)\n",
        "\n",
        "    train_loader = DataLoader(JigsawDataset(train_df, tokenizer, config[\"max_len\"]),\n",
        "                              batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(JigsawDataset(val_df, tokenizer, config[\"max_len\"]),\n",
        "                            batch_size=config[\"batch_size\"])\n",
        "\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(config[\"model_name\"])\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"total_epochs\"]):\n",
        "        start = time.time()\n",
        "\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} Acc={train_acc:.4f} | Val Loss={val_loss:.4f} Acc={val_acc:.4f} | Time={time.time() - start:.2f}s\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), args.save_path)\n",
        "            patience_counter = 0\n",
        "            print(\"  Validation loss improved. Model saved.\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  No improvement. Patience: {patience_counter}\")\n",
        "            if patience_counter >= config[\"patience\"]:\n",
        "                print(\"  Early stopping.\")\n",
        "                break"
      ],
      "metadata": {
        "id": "MWPCEBp17Yk0"
      },
      "id": "MWPCEBp17Yk0",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate arguments\n",
        "class args:\n",
        "  data_dir = \"data/jigsaw/processed/\"\n",
        "  save_path = \"models/model.pth\"\n",
        "  dry_run = False\n",
        "\n",
        "main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1sjxCQx-edf",
        "outputId": "22a6acfe-8d6e-4865-bfd1-231f81136d1b"
      },
      "id": "v1sjxCQx-edf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 564 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 23/11281 [00:09<1:17:57,  2.41it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Optimization"
      ],
      "metadata": {
        "id": "k8e-A7-c9oC_"
      },
      "id": "k8e-A7-c9oC_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure inference performance of PyTorch model on CPU"
      ],
      "metadata": {
        "id": "kiaqcCvfCA12"
      },
      "id": "kiaqcCvfCA12"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "id": "qkzLnieUCItb"
      },
      "id": "qkzLnieUCItb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from torchinfo import summary\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JcGYc7QZ9o4F"
      },
      "id": "JcGYc7QZ9o4F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure inference performance of ONNX model on CPU¶"
      ],
      "metadata": {
        "id": "WlQQOubWCD-Q"
      },
      "id": "WlQQOubWCD-Q"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B9a2EukdCHQS"
      },
      "id": "B9a2EukdCHQS",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}