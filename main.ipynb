{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d3dd957d",
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        },
        "id": "d3dd957d"
      },
      "source": [
        "# Inference Optimizations\n",
        "Note: used google collab for GPU because of time constraint. \\\n",
        "In real pipeline this would be done after training on GPU instance."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-process Data"
      ],
      "metadata": {
        "id": "kj8Izgcb689h"
      },
      "id": "kj8Izgcb689h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "# Move to the correct path\n",
        "!mkdir -p /content/.kaggle\n",
        "!cp kaggle.json /content/.kaggle/\n",
        "!chmod 600 /content/.kaggle/kaggle.json\n",
        "\n",
        "# Set the environment variable so the API knows where to look\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/.kaggle\"\n",
        "\n",
        "# Test\n",
        "!kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "2YjN67g88YE-",
        "outputId": "dce9be3b-2507-4c77-e56b-b97adad6439f"
      },
      "id": "2YjN67g88YE-",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7deb441d-142a-48dc-ac1b-7b114edc06cd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7deb441d-142a-48dc-ac1b-7b114edc06cd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "ref                                                          title                                                      size  lastUpdated                 downloadCount  voteCount  usabilityRating  \n",
            "-----------------------------------------------------------  --------------------------------------------------  -----------  --------------------------  -------------  ---------  ---------------  \n",
            "jayaantanaath/student-habits-vs-academic-performance         Student Habits vs Academic Performance                    19512  2025-04-12 10:49:08.663000          23391        402  1.0              \n",
            "adilshamim8/cost-of-international-education                  Cost of International Education                           18950  2025-05-07 15:41:53.213000           4695         79  1.0              \n",
            "adilshamim8/social-media-addiction-vs-relationships          Students' Social Media Addiction                           7851  2025-05-10 14:38:02.713000           2176         35  1.0              \n",
            "fatemehmohammadinia/heart-attack-dataset-tarik-a-rashid      Heart Attack Dataset                                      16250  2025-04-30 21:58:22.740000           4573         80  1.0              \n",
            "ivankmk/thousand-ml-jobs-in-usa                              Machine Learning Job Postings in the US                 1682058  2025-04-20 16:11:59.347000           4498         99  1.0              \n",
            "michaelmatta0/global-development-indicators-2000-2020        Global Development Full Analysis (2000-2020)            1311638  2025-05-11 16:57:19.013000            791         26  1.0              \n",
            "mahdimashayekhi/fake-news-detection-dataset                  Fake News Detection Dataset                            11735585  2025-04-27 14:52:10.607000           1969         26  1.0              \n",
            "aryan208/financial-transactions-dataset-for-fraud-detection  Financial Transactions Dataset for Fraud Detection    290256858  2025-05-02 09:12:28.203000           1227         29  1.0              \n",
            "umeradnaan/daily-social-media-active-users                   Daily Social Media Active Users                          126814  2025-05-05 02:11:50.873000           1700         23  1.0              \n",
            "khushikyad001/impact-of-screen-time-on-mental-health         Impact of Screen Time on Mental Health                    64873  2025-04-20 18:01:47.570000           2770         43  1.0              \n",
            "dnkumars/cryptocurrency-transaction-analytics-btc-and-eth    Cryptocurrency Transaction Analytics: BTC & ETH         5167978  2025-05-11 15:16:52.107000            409         30  1.0              \n",
            "madhuraatmarambhagat/crop-recommendation-dataset             Crop Recommendation Dataset                               65234  2025-05-08 17:02:09.397000            799         27  1.0              \n",
            "zahidmughal2343/global-cancer-patients-2015-2024             global_cancer_patients_2015_2024                        1261049  2025-04-14 00:05:23.367000           5249         65  1.0              \n",
            "razanaqvi14/real-and-fake-news                               Real & Fake News                                       42975911  2025-04-28 19:46:53.073000           1066         22  1.0              \n",
            "adilshamim8/greenhouse-plant-growth-metrics                  Greenhouse Plant Growth                                 3041046  2025-04-19 07:33:57.787000           1802         28  1.0              \n",
            "wikimedia-foundation/wikipedia-structured-contents           Wikipedia Structured Contents                       25121685657  2025-04-11 07:11:03.397000           2246        287  0.8125           \n",
            "glowstudygram/spotify-songs-and-artists-dataset              Spotify Songs and Artists Dataset | Audio Features        68415  2025-04-27 12:38:36.850000           1873         31  0.8235294        \n",
            "nikolasgegenava/sneakers-classification                      Popular Sneakers Classification                        17981294  2025-05-01 12:00:45.517000           1612         43  1.0              \n",
            "palvinder2006/ola-bike-ride-request                          Ola Bike Ride Request                                    174975  2025-04-28 03:55:33.860000           1100         28  1.0              \n",
            "adilshamim8/predict-students-dropout-and-academic-success    Student Dropout & Success Prediction Dataset             106181  2025-04-23 06:34:06.433000           2526         39  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "\n",
        "# os.environ[\"KAGGLE_CONFIG_DIR\"] = os.path.abspath(\".kaggle\") # Use local .kaggle directory\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi"
      ],
      "metadata": {
        "id": "brjGUd9A74BN"
      },
      "id": "brjGUd9A74BN",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_jigsaw(kaggle_dir):\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    # Download competition data\n",
        "    api.competition_download_files(\n",
        "        \"jigsaw-unintended-bias-in-toxicity-classification\",\n",
        "        path=kaggle_dir\n",
        "    )\n",
        "\n",
        "    # Unzip\n",
        "    zip_path = os.path.join(kaggle_dir, \"jigsaw-unintended-bias-in-toxicity-classification.zip\")\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(kaggle_dir)\n",
        "\n",
        "    print(\"Downloaded and extracted Jigsaw dataset.\")\n",
        "\n",
        "\n",
        "def preprocess(kaggle_dir, output_dir, split_ratio=0.2):\n",
        "    # Create output directory if missing\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Ensure input file exists, create parent dir if needed (just in case)\n",
        "    os.makedirs(kaggle_dir, exist_ok=True)\n",
        "    input_path = os.path.join(kaggle_dir, \"train.csv\")\n",
        "    if not os.path.exists(input_path):\n",
        "        raise FileNotFoundError(f\"train.csv not found in {kaggle_dir}\")\n",
        "\n",
        "    df = pd.read_csv(input_path).dropna(subset=[\"comment_text\"])\n",
        "\n",
        "    # Keep only the needed columns\n",
        "    df = df[[\"comment_text\", \"target\"]]\n",
        "\n",
        "    # Binarize target (optional: uncomment if needed)\n",
        "    # df[\"target\"] = (df[\"target\"] >= 0.5).astype(int)\n",
        "\n",
        "    # Split\n",
        "    train_df, val_df = train_test_split(df, test_size=split_ratio, random_state=42)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    train_df.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
        "    val_df.to_csv(os.path.join(output_dir, \"val.csv\"), index=False)\n",
        "\n",
        "    print(f\"Saved {len(train_df)} training and {len(val_df)} validation samples to {output_dir}\")"
      ],
      "metadata": {
        "id": "wlF8J4Je72OJ"
      },
      "id": "wlF8J4Je72OJ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_dir = \"data/jigsaw/raw/\"\n",
        "output_dir = \"data/jigsaw/processed/\"\n",
        "val_split = 0.2\n",
        "\n",
        "download_jigsaw(kaggle_dir)\n",
        "preprocess(kaggle_dir, output_dir, val_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s83yLZkY784G",
        "outputId": "b963bf02-0338-4275-d10c-fd3156d0be29"
      },
      "id": "s83yLZkY784G",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded and extracted Jigsaw dataset.\n",
            "Saved 1443896 training and 360975 validation samples to data/jigsaw/processed/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "W6WLW_2G7z2B"
      },
      "id": "W6WLW_2G7z2B"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification"
      ],
      "metadata": {
        "id": "zGBzK-M26-VF"
      },
      "id": "zGBzK-M26-VF",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"initial_epochs\": 2,\n",
        "    \"total_epochs\": 1,\n",
        "    \"patience\": 2,\n",
        "    \"batch_size\": 128,\n",
        "    \"lr\": 2e-5,\n",
        "    \"fine_tune_lr\": 1e-5,\n",
        "    \"max_len\": 128,\n",
        "    \"dropout_probability\": 0.3,\n",
        "    \"model_name\": \"distilbert-base-uncased\"\n",
        "}"
      ],
      "metadata": {
        "id": "68nz89tK6Kmo"
      },
      "id": "68nz89tK6Kmo",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Dataset\n",
        "# ---------------------------\n",
        "class JigsawDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.texts = df[\"comment_text\"].tolist()\n",
        "        self.labels = (df[\"target\"] >= 0.5).astype(int).tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "KSfh49tW6unS"
      },
      "id": "KSfh49tW6unS",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Training + Evaluation Functions\n",
        "# ---------------------------\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device, portion=0.01):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    num_batches = int(portion * len(loader)) # Doing part of the training because my part is inference and monitoring\n",
        "    print(f\"Training for {num_batches} batches\")\n",
        "\n",
        "    for i, batch in enumerate(tqdm(loader, desc=\"Training\", leave=False)):\n",
        "        if i >= num_batches:\n",
        "            break\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.logits.argmax(dim=1)\n",
        "        correct += (preds == batch[\"labels\"]).sum().item()\n",
        "        total += batch[\"labels\"].size(0)\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_acc = correct / total\n",
        "    print(f\"Partial Epoch Summary - Avg Loss: {avg_loss:.4f}, Avg Accuracy: {avg_acc:.4f}\\n\")\n",
        "\n",
        "    return avg_loss, avg_acc\n",
        "\n",
        "def evaluate(model, loader, criterion, device, portion=0.01):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    num_batches = int(portion * len(loader))\n",
        "    print(f\"Evaluating for {num_batches} batches\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(loader, desc=\"Evaluating\", leave=False)):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            correct += (preds == batch[\"labels\"]).sum().item()\n",
        "            total += batch[\"labels\"].size(0)\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_acc = correct / total\n",
        "    print(f\"Eval Summary - Avg Loss: {avg_loss:.4f}, Accuracy: {avg_acc:.4f}\\n\")\n",
        "\n",
        "    return avg_loss, avg_acc"
      ],
      "metadata": {
        "id": "QJrmvVAy6ys6"
      },
      "id": "QJrmvVAy6ys6",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Main Training Pipeline\n",
        "# ---------------------------\n",
        "def main(args):\n",
        "    # made to run in command line originally\n",
        "    # parser = argparse.ArgumentParser()\n",
        "    # parser.add_argument(\"--data-dir\", type=str, required=True, help=\"Directory with train.csv and val.csv\")\n",
        "    # parser.add_argument(\"--save-path\", type=str, required=True, help=\"Path to save the trained model\")\n",
        "    # parser.add_argument(\"--dry-run\", action=\"store_true\", help=\"Run a quick test on a small sample\")\n",
        "    # args = parser.parse_args()\n",
        "\n",
        "    os.makedirs(os.path.dirname(args.save_path), exist_ok=True)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(config[\"model_name\"])\n",
        "    train_df = pd.read_csv(os.path.join(args.data_dir, \"train.csv\"))\n",
        "    if args.dry_run:\n",
        "        train_df = train_df.sample(n=32, random_state=42)\n",
        "    val_df = pd.read_csv(os.path.join(args.data_dir, \"val.csv\"))\n",
        "    if args.dry_run:\n",
        "        val_df = val_df.sample(n=32, random_state=42)\n",
        "\n",
        "    train_loader = DataLoader(JigsawDataset(train_df, tokenizer, config[\"max_len\"]),\n",
        "                              batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(JigsawDataset(val_df, tokenizer, config[\"max_len\"]),\n",
        "                            batch_size=config[\"batch_size\"])\n",
        "\n",
        "    model = DistilBertForSequenceClassification.from_pretrained(config[\"model_name\"])\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(config[\"total_epochs\"]):\n",
        "        start = time.time()\n",
        "\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f} Acc={train_acc:.4f} | Val Loss={val_loss:.4f} Acc={val_acc:.4f} | Time={time.time() - start:.2f}s\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), args.save_path)\n",
        "            patience_counter = 0\n",
        "            print(\"  Validation loss improved. Model saved.\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  No improvement. Patience: {patience_counter}\")\n",
        "            if patience_counter >= config[\"patience\"]:\n",
        "                print(\"  Early stopping.\")\n",
        "                break"
      ],
      "metadata": {
        "id": "MWPCEBp17Yk0"
      },
      "id": "MWPCEBp17Yk0",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate arguments\n",
        "class args:\n",
        "  data_dir = \"data/jigsaw/processed/\"\n",
        "  save_path = \"models/model.pth\"\n",
        "  dry_run = False\n",
        "\n",
        "main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "a8b4bc5064ca44e5b574d8c0eb815258",
            "9b1d131a8a924326a24a7779e37ab2c0",
            "552808e00445482fa25dd65ff6195466",
            "d91cef8296cb40028c1d65d4287dbe48",
            "48cb8e36b85948f4ab4ea3058d7dd83c",
            "c3059fd8ffac4bad89d43b113f06e215",
            "4791f89c223b4ddc8cc1f26a981548ec",
            "57d46d264e72446fa4729886ad7a88eb",
            "bc11b20cb2a8495cac4277a6c926648f",
            "db54ed068fcf464ebcf87b70fe1fe4d6",
            "6a909ffe347a4802b0a9fc06c4e2ac48",
            "5b21567ffe254d18be83e9d6f7b3daf8",
            "ba91cbd81a2644018e57f5f20579a801",
            "2b3df0119d8141e4b3056372078878c0",
            "c2142ccef0b2416daea74ea7f8fa427b",
            "ac6243d0c50d4bfea68c046023b187d7",
            "0f001922f43945aa83206f58ecd88f61",
            "d7829b14f1ae4713b259ec0d65125ca6",
            "cf96061926634408a261ec9a6179310c",
            "75d3847c087248fe9aee44a5452333cd",
            "f38aea8065a248a39b267e1407a1e1dc",
            "6af0fc9b6b38474aa0b1e4b4db82cb8b",
            "d840043e798e4b6584413a175b39b104",
            "6c4e42f38f03418c8f4edcf71aeb6d1c",
            "cc6de4e7c0d046f8b562968e859a5386",
            "b2c66d5a942b439d959cc7ee86fafd14",
            "3bc1be7acef54af0baefc6ce2bd71198",
            "2f6c0dee16694cd794158530feaa7645",
            "bf020a77ece94878ab91527a7cb5c3e7",
            "257862580509429db0a597daa1c509d5",
            "41bf3f1452264fedaf4acc619d15aa56",
            "f00460674c014065bd851c335f7affdf",
            "9506f5f3307c41d78def18a4e99f3d3f",
            "2e96ae2ef1fc41c087985fc44db1f03a",
            "51310bb0ae2b47ab936b913479d0ab79",
            "2f5239aa309a4c42a6d169626b9f5606",
            "5789692fe5e748eba6d779b8e1c096db",
            "d446770c77104531b801feee3a0180df",
            "14e20ddd683a41ac807e86d21233958c",
            "7ea2bde798bb4e61b2cb7707154767ba",
            "9b9499cbc8f941dbb338ed41d850d759",
            "f4a86af5669b4fee947da12780c31f57",
            "0d73701e68764559bcba8a76cbd50ded",
            "9b48d0f1174047648a6255f57f8fa611",
            "e9092286bd814786b36f10ae258cb21e",
            "4f05f093f70d4f82958ea95943868ea2",
            "03e784427660462eba19a57b98183b3b",
            "38301cc877324982be7ad8949bb3cbbb",
            "083c6078f1ea4852a7591308040982d0",
            "498d5115765141b8a25a1d8555c8f7cb",
            "4b09b712f06442a8920c416c4c9a2e6a",
            "641c615cc23e46a0989b7226eece3662",
            "ee7a9c035a9142178b9c2a16bdf29110",
            "a543b2148cc34d2b9c54fbe5d012e28a",
            "883c7452c491455589f9182b78ca4d28"
          ]
        },
        "id": "v1sjxCQx-edf",
        "outputId": "aaec3e5b-c9a5-4455-d11d-6826d04d9caa"
      },
      "id": "v1sjxCQx-edf",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8b4bc5064ca44e5b574d8c0eb815258"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b21567ffe254d18be83e9d6f7b3daf8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d840043e798e4b6584413a175b39b104"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e96ae2ef1fc41c087985fc44db1f03a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9092286bd814786b36f10ae258cb21e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 112 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partial Epoch Summary - Avg Loss: 0.2503, Avg Accuracy: 0.9166\n",
            "\n",
            "Evaluating for 28 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval Summary - Avg Loss: 0.1531, Accuracy: 0.9481\n",
            "\n",
            "Epoch 1: Train Loss=0.2503 Acc=0.9166 | Val Loss=0.1531 Acc=0.9481 | Time=53.61s\n",
            "  Validation loss improved. Model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference Optimization"
      ],
      "metadata": {
        "id": "k8e-A7-c9oC_"
      },
      "id": "k8e-A7-c9oC_"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkzLnieUCItb",
        "outputId": "c6145af9-6714-4dc5-bd05-0f73f028078d"
      },
      "id": "qkzLnieUCItb",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "from torchinfo import summary\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "JcGYc7QZ9o4F"
      },
      "id": "JcGYc7QZ9o4F",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class JigsawDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, max_len):\n",
        "        self.texts = df[\"comment_text\"].tolist()\n",
        "        self.labels = (df[\"target\"] >= 0.5).astype(int).tolist()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inputs = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_len,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
        "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "NwXGzxLoHIss"
      },
      "id": "NwXGzxLoHIss",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "max_len = 128\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "dataset_dir = os.getenv(\"DATA_DIR\", \"data/jigsaw/processed\")\n",
        "model_path = \"models/model.pth\""
      ],
      "metadata": {
        "id": "fUFo_RINHMzx"
      },
      "id": "fUFo_RINHMzx",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_df = pd.read_csv(os.path.join(dataset_dir, \"val.csv\"))\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "test_loader = DataLoader(JigsawDataset(val_df, tokenizer, max_len), batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "WBvbzUaXHNaU"
      },
      "id": "WBvbzUaXHNaU",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure inference performance of PyTorch model on CPU"
      ],
      "metadata": {
        "id": "D_94H62kHLOu"
      },
      "id": "D_94H62kHLOu"
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
        "state_dict = torch.load(model_path, map_location=device)\n",
        "model.load_state_dict(state_dict)\n",
        "model.compile() # Test Compile mode\n",
        "model.eval()\n",
        "summary(model)"
      ],
      "metadata": {
        "id": "twIapCTmvbVJ",
        "outputId": "51e37ba3-bc0f-4c1c-e11d-6c28b2f9f29b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "twIapCTmvbVJ",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "================================================================================\n",
              "Layer (type:depth-idx)                                  Param #\n",
              "================================================================================\n",
              "DistilBertForSequenceClassification                     --\n",
              "├─DistilBertModel: 1-1                                  --\n",
              "│    └─Embeddings: 2-1                                  --\n",
              "│    │    └─Embedding: 3-1                              23,440,896\n",
              "│    │    └─Embedding: 3-2                              393,216\n",
              "│    │    └─LayerNorm: 3-3                              1,536\n",
              "│    │    └─Dropout: 3-4                                --\n",
              "│    └─Transformer: 2-2                                 --\n",
              "│    │    └─ModuleList: 3-5                             42,527,232\n",
              "├─Linear: 1-2                                           590,592\n",
              "├─Linear: 1-3                                           1,538\n",
              "├─Dropout: 1-4                                          --\n",
              "================================================================================\n",
              "Total params: 66,955,010\n",
              "Trainable params: 66,955,010\n",
              "Non-trainable params: 0\n",
              "================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = os.path.getsize(model_path)\n",
        "print(f\"Model Size on Disk: {model_size/ (1e6) :.2f} MB\")"
      ],
      "metadata": {
        "id": "ts-e_SnJvlqB",
        "outputId": "d39298da-0cdd-4377-baf7-1d8c64b27cc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "ts-e_SnJvlqB",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size on Disk: 267.85 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_test(model, loader, device, portion=0.01):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    num_batches = int(portion * len(loader))\n",
        "    print(f\"Evaluating for {num_batches} batches\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(tqdm(loader, desc=\"Evaluating\", leave=False)):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            preds = outputs.logits.argmax(dim=1)\n",
        "            correct += (preds == batch[\"labels\"]).sum().item()\n",
        "            total += batch[\"labels\"].size(0)\n",
        "\n",
        "    return correct, total"
      ],
      "metadata": {
        "id": "jtAMTLh2wGYK"
      },
      "id": "jtAMTLh2wGYK",
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct, total = evaluate_test(model, test_loader, device, portion=0.01)\n",
        "accuracy = (correct / total) * 100\n",
        "print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total} correct)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxzuJtb3voNE",
        "outputId": "aa168b1a-0b81-4272-ae1f-6184810f8654"
      },
      "id": "vxzuJtb3voNE",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating for 28 batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.81% (3398/3584 correct)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference Latency"
      ],
      "metadata": {
        "id": "8hqE-v5Nwpq1"
      },
      "id": "8hqE-v5Nwpq1"
    },
    {
      "cell_type": "code",
      "source": [
        "num_trials = 100\n",
        "\n",
        "# 1) get one batch as a dict\n",
        "batch = next(iter(test_loader))\n",
        "# 2) extract the first example and move to device\n",
        "input_ids      = batch[\"input_ids\"][0].unsqueeze(0).to(device)\n",
        "attention_mask = batch[\"attention_mask\"][0].unsqueeze(0).to(device)\n",
        "\n",
        "model.eval()\n",
        "# 3) warm-up\n",
        "with torch.no_grad():\n",
        "    _ = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "# 4) timed runs\n",
        "latencies = []\n",
        "for _ in range(num_trials):\n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        _ = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    latencies.append(time.perf_counter() - start)"
      ],
      "metadata": {
        "id": "LCGGR__Yvqqj"
      },
      "id": "LCGGR__Yvqqj",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Inference Latency (single sample, median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
        "print(f\"Inference Latency (single sample, 95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
        "print(f\"Inference Latency (single sample, 99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
        "print(f\"Inference Throughput (single sample): {num_trials/np.sum(latencies):.2f} FPS\")"
      ],
      "metadata": {
        "id": "HG7xz3erwt3v",
        "outputId": "bccd329c-d495-48bf-a0ba-a47a8d48d2f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HG7xz3erwt3v",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Latency (single sample, median): 31.67 ms\n",
            "Inference Latency (single sample, 95th percentile): 44.55 ms\n",
            "Inference Latency (single sample, 99th percentile): 45.59 ms\n",
            "Inference Throughput (single sample): 29.51 FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Batch throughput"
      ],
      "metadata": {
        "id": "D6AS3pLTw1HL"
      },
      "id": "D6AS3pLTw1HL"
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = 10  # Number of trials\n",
        "\n",
        "# 1) Grab one batch (a dict) and move to device, dropping labels\n",
        "batch = next(iter(test_loader))\n",
        "batch = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# 2) Warm-up\n",
        "with torch.no_grad():\n",
        "    model(**batch)\n",
        "\n",
        "# 3) Timed runs\n",
        "batch_times = []\n",
        "for _ in range(num_batches):\n",
        "    start = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        model(**batch)\n",
        "    batch_times.append(time.perf_counter() - start)"
      ],
      "metadata": {
        "id": "dgYn-pGQw1ra"
      },
      "id": "dgYn-pGQw1ra",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume `batch` is the dict you moved to device and `batch_times` is your list of durations\n",
        "batch_size    = batch[\"input_ids\"].shape[0]\n",
        "total_samples = batch_size * num_batches\n",
        "batch_fps     = total_samples / np.sum(batch_times)\n",
        "\n",
        "print(f\"Batch Throughput: {batch_fps:.2f} FPS\")"
      ],
      "metadata": {
        "id": "HgmK33Nxw5Kv",
        "outputId": "2858a716-4c56-436e-882c-116d59a6291d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "HgmK33Nxw5Kv",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Throughput: 52.82 FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary"
      ],
      "metadata": {
        "id": "VRN1vHcWw_wK"
      },
      "id": "VRN1vHcWw_wK"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model Size on Disk: {model_size/ (1e6) :.2f} MB\")\n",
        "print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total} correct)\")\n",
        "print(f\"Inference Latency (single sample, median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
        "print(f\"Inference Latency (single sample, 95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
        "print(f\"Inference Latency (single sample, 99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
        "print(f\"Inference Throughput (single sample): {num_trials/np.sum(latencies):.2f} FPS\")\n",
        "print(f\"Batch Throughput: {batch_fps:.2f} FPS\")"
      ],
      "metadata": {
        "id": "9hpuiP8Ew-QV",
        "outputId": "1c902714-1000-4164-eb7e-24e0d6c729fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9hpuiP8Ew-QV",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size on Disk: 267.85 MB\n",
            "Accuracy: 94.81% (3398/3584 correct)\n",
            "Inference Latency (single sample, median): 31.67 ms\n",
            "Inference Latency (single sample, 95th percentile): 44.55 ms\n",
            "Inference Latency (single sample, 99th percentile): 45.59 ms\n",
            "Inference Throughput (single sample): 29.51 FPS\n",
            "Batch Throughput: 52.82 FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Eager mode Summary**\n",
        "Model Size on Disk: 267.85 MB \\\n",
        "Accuracy: 94.81% (3398/3584 correct) \\\n",
        "Inference Latency (single sample, median): 35.32 ms \\\n",
        "Inference Latency (single sample, 95th percentile): 55.24 ms \\\n",
        "Inference Latency (single sample, 99th percentile): 56.10 ms \\\n",
        "Inference Throughput (single sample): 26.91 FPS \\\n",
        "Batch Throughput: 40.85 FPS \\\n",
        "\n",
        "#### **Compiled Summary**\n",
        "Model Size on Disk: 267.85 MB \\\n",
        "Accuracy: 94.81% (3398/3584 correct) \\\n",
        "Inference Latency (single sample, median): 31.67 ms \\\n",
        "Inference Latency (single sample, 95th percentile): 44.55 ms \\\n",
        "Inference Latency (single sample, 99th percentile): 45.59 ms \\\n",
        "Inference Throughput (single sample): 29.51 FPS \\\n",
        "Batch Throughput: 52.82 FPS \\"
      ],
      "metadata": {
        "id": "v0a1JSqjxHoC"
      },
      "id": "v0a1JSqjxHoC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measure inference performance of ONNX model on CPU¶"
      ],
      "metadata": {
        "id": "WlQQOubWCD-Q"
      },
      "id": "WlQQOubWCD-Q"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx onnxruntime"
      ],
      "metadata": {
        "id": "Yxl8fQkUG3K7",
        "outputId": "487d5398-9ba8-4d6a-ba01-9dcb94a6442d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Yxl8fQkUG3K7",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (5.29.4)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.11/dist-packages (from onnx) (4.13.2)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (24.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m88.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.18.0 onnxruntime-1.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "import onnxruntime as ort"
      ],
      "metadata": {
        "id": "B9a2EukdCHQS"
      },
      "id": "B9a2EukdCHQS",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cpu\")\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
        "state_dict = torch.load(model_path, map_location=device)\n",
        "model.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "fQ3JXMp4HAIt",
        "outputId": "6fadd689-6da7-4c60-a4f3-370b530ac754",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fQ3JXMp4HAIt",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = \"models/model.onnx\"\n",
        "\n",
        "# dummy input - used to clarify the input shape\n",
        "batch_size = 1\n",
        "seq_len    = max_len\n",
        "dummy_input_ids = torch.randint(\n",
        "    low=0,\n",
        "    high=tokenizer.vocab_size,\n",
        "    size=(batch_size, seq_len),\n",
        "    dtype=torch.long,\n",
        "    device=model.device\n",
        ")\n",
        "dummy_attention_mask = torch.ones(\n",
        "    (batch_size, seq_len),\n",
        "    dtype=torch.long,\n",
        "    device=model.device\n",
        ")\n",
        "\n",
        "# export\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    (dummy_input_ids, dummy_attention_mask),\n",
        "    onnx_model_path,\n",
        "    export_params=True,\n",
        "    opset_version=14,\n",
        "    do_constant_folding=True,\n",
        "    input_names=[\"input_ids\", \"attention_mask\"],\n",
        "    output_names=[\"logits\"],\n",
        "    dynamic_axes={\n",
        "        \"input_ids\":       {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        \"attention_mask\":  {0: \"batch_size\", 1: \"seq_len\"},\n",
        "        \"logits\":          {0: \"batch_size\"}\n",
        "    }\n",
        ")\n",
        "\n",
        "# sanity check\n",
        "onnx_model = onnx.load(onnx_model_path)\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "metadata": {
        "id": "KBpJ0ljSHY0V"
      },
      "id": "KBpJ0ljSHY0V",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = os.path.getsize(onnx_model_path)\n",
        "print(f\"Model Size on Disk: {model_size/ (1e6) :.2f} MB\")"
      ],
      "metadata": {
        "id": "hYECqMXnyfdU",
        "outputId": "43ce4a0c-1382-4ed5-fc4b-fd06203569a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hYECqMXnyfdU",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Size on Disk: 267.96 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create inference session"
      ],
      "metadata": {
        "id": "sRZdA5xKx1S3"
      },
      "id": "sRZdA5xKx1S3"
    },
    {
      "cell_type": "code",
      "source": [
        "ort_session = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])\n",
        "ort_session.get_providers()"
      ],
      "metadata": {
        "id": "PjjTPxHrHgtw",
        "outputId": "d3d1f035-8b84-4351-c368-4a3a5bf66b64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PjjTPxHrHgtw",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CPUExecutionProvider']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "num_samples = int(0.0001 * len(test_loader.dataset))\n",
        "samples_tested = 0\n",
        "\n",
        "for batch in test_loader:\n",
        "    if samples_tested >= num_samples:\n",
        "        break\n",
        "\n",
        "    input_ids = batch[\"input_ids\"].numpy()\n",
        "    attention_mask = batch[\"attention_mask\"].numpy()\n",
        "    labels = batch[\"labels\"].numpy()\n",
        "\n",
        "    outputs = ort_session.run(None, {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask\n",
        "    })[0]\n",
        "\n",
        "    predicted = np.argmax(outputs, axis=1)\n",
        "    batch_size = labels.shape[0]\n",
        "    correct += (predicted == labels).sum()\n",
        "    total += batch_size\n",
        "    samples_tested += batch_size\n",
        "\n",
        "accuracy = (correct / total) * 100"
      ],
      "metadata": {
        "id": "MEbcKP1fy3EW"
      },
      "id": "MEbcKP1fy3EW",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total} correct)\")"
      ],
      "metadata": {
        "id": "33qjU9cBzuly",
        "outputId": "1634bca1-ea84-4ccc-987d-23dcc4137374",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "33qjU9cBzuly",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.09% (123/128 correct)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Inference Latency"
      ],
      "metadata": {
        "id": "65-XRZcdz9MJ"
      },
      "id": "65-XRZcdz9MJ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare a single tokenized sample\n",
        "model_input = tokenizer(\"This is a sample.\", return_tensors=\"np\", max_length=max_len, padding=\"max_length\", truncation=True)\n",
        "single_input_ids = model_input[\"input_ids\"]\n",
        "single_attention_mask = model_input[\"attention_mask\"]\n",
        "\n",
        "# Setup ONNX Runtime session\n",
        "ort_session = ort.InferenceSession(\"models/model.onnx\")\n",
        "\n",
        "# Warm-up\n",
        "ort_session.run(None, {\n",
        "    \"input_ids\": single_input_ids,\n",
        "    \"attention_mask\": single_attention_mask\n",
        "})\n",
        "\n",
        "# Timing\n",
        "latencies = []\n",
        "for _ in range(100):\n",
        "    start = time.time()\n",
        "    ort_session.run(None, {\n",
        "        \"input_ids\": single_input_ids,\n",
        "        \"attention_mask\": single_attention_mask\n",
        "    })\n",
        "    latencies.append(time.time() - start)"
      ],
      "metadata": {
        "id": "HfWvfN47HnTu"
      },
      "id": "HfWvfN47HnTu",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Inference Latency (single sample, median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
        "print(f\"Inference Latency (single sample, 95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
        "print(f\"Inference Latency (single sample, 99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
        "print(f\"Inference Throughput (single sample): {num_trials/np.sum(latencies):.2f} FPS\")"
      ],
      "metadata": {
        "id": "nox0neZ8y3dI",
        "outputId": "da99a752-30eb-4c2a-f1cb-d46e8e851951",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "nox0neZ8y3dI",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inference Latency (single sample, median): 40.11 ms\n",
            "Inference Latency (single sample, 95th percentile): 40.53 ms\n",
            "Inference Latency (single sample, 99th percentile): 41.30 ms\n",
            "Inference Throughput (single sample): 24.92 FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Batch Throughput"
      ],
      "metadata": {
        "id": "gwjQH4ihz-_1"
      },
      "id": "gwjQH4ihz-_1"
    },
    {
      "cell_type": "code",
      "source": [
        "num_batches = 50\n",
        "\n",
        "# Get a batch from the test data\n",
        "batch = next(iter(test_loader))\n",
        "input_ids = batch[\"input_ids\"].numpy()\n",
        "attention_mask = batch[\"attention_mask\"].numpy()\n",
        "\n",
        "# Warm-up\n",
        "ort_session.run(None, {\n",
        "    \"input_ids\": input_ids,\n",
        "    \"attention_mask\": attention_mask\n",
        "})\n",
        "\n",
        "batch_times = []\n",
        "for _ in range(num_batches):\n",
        "    start_time = time.time()\n",
        "    ort_session.run(None, {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask\n",
        "    })\n",
        "    batch_times.append(time.time() - start_time)"
      ],
      "metadata": {
        "id": "Mb3w2EoqzfGL"
      },
      "id": "Mb3w2EoqzfGL",
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_fps = (input_ids.shape[0] * num_batches) / np.sum(batch_times)\n",
        "print(f\"Batch Throughput: {batch_fps:.2f} FPS\")"
      ],
      "metadata": {
        "id": "BUYsZh_U0FwO",
        "outputId": "6360d2fe-6290-4f37-a554-3f4bbbdbdf43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "BUYsZh_U0FwO",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Throughput: 41.60 FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Summary"
      ],
      "metadata": {
        "id": "LQpOgxZq0Rt1"
      },
      "id": "LQpOgxZq0Rt1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy:.2f}% ({correct}/{total} correct)\")\n",
        "print(f\"Model Size on Disk: {model_size/ (1e6) :.2f} MB\")\n",
        "print(f\"Inference Latency (single sample, median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
        "print(f\"Inference Latency (single sample, 95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
        "print(f\"Inference Latency (single sample, 99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
        "print(f\"Inference Throughput (single sample): {num_trials/np.sum(latencies):.2f} FPS\")\n",
        "print(f\"Batch Throughput: {batch_fps:.2f} FPS\")"
      ],
      "metadata": {
        "id": "gtixPydh0GJL",
        "outputId": "e9a0dd55-f026-428e-ef5a-9c30092cc8eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gtixPydh0GJL",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96.09% (123/128 correct)\n",
            "Model Size on Disk: 267.96 MB\n",
            "Inference Latency (single sample, median): 40.11 ms\n",
            "Inference Latency (single sample, 95th percentile): 40.53 ms\n",
            "Inference Latency (single sample, 99th percentile): 41.30 ms\n",
            "Inference Throughput (single sample): 24.92 FPS\n",
            "Batch Throughput: 41.60 FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Apply optimizations to ONNX model"
      ],
      "metadata": {
        "id": "2_LFg3-I0pQ2"
      },
      "id": "2_LFg3-I0pQ2"
    },
    {
      "cell_type": "code",
      "source": [
        "def benchmark_session(ort_session):\n",
        "    print(f\"Execution provider: {ort_session.get_providers()}\")\n",
        "\n",
        "    ## Benchmark accuracy (0.01% of test set)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    num_samples = int(0.0001 * len(test_loader.dataset))\n",
        "    samples_tested = 0\n",
        "\n",
        "    for batch in test_loader:\n",
        "        if samples_tested >= num_samples:\n",
        "            break\n",
        "\n",
        "        input_ids = batch[\"input_ids\"].numpy()\n",
        "        attention_mask = batch[\"attention_mask\"].numpy()\n",
        "        labels = batch[\"labels\"].numpy()\n",
        "\n",
        "        outputs = ort_session.run(None, {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask\n",
        "        })[0]\n",
        "\n",
        "        predicted = np.argmax(outputs, axis=1)\n",
        "        batch_size = labels.shape[0]\n",
        "        correct += (predicted == labels).sum()\n",
        "        total += batch_size\n",
        "        samples_tested += batch_size\n",
        "\n",
        "    accuracy = (correct / total) * 100\n",
        "    print(f\"Accuracy (0.01% sampled): {accuracy:.2f}% ({correct}/{total} correct)\")\n",
        "\n",
        "    ## Benchmark inference latency for single sample\n",
        "    num_trials = 100\n",
        "    single_batch = next(iter(test_loader))\n",
        "    input_ids = single_batch[\"input_ids\"][:1].numpy()\n",
        "    attention_mask = single_batch[\"attention_mask\"][:1].numpy()\n",
        "\n",
        "    ort_session.run(None, {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask\n",
        "    })\n",
        "\n",
        "    latencies = []\n",
        "    for _ in range(num_trials):\n",
        "        start = time.time()\n",
        "        ort_session.run(None, {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask\n",
        "        })\n",
        "        latencies.append(time.time() - start)\n",
        "\n",
        "    print(f\"Inference Latency (single sample, median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
        "    print(f\"Inference Latency (single sample, 95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
        "    print(f\"Inference Latency (single sample, 99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
        "    print(f\"Inference Throughput (single sample): {num_trials / np.sum(latencies):.2f} FPS\")\n",
        "\n",
        "    ## Benchmark batch throughput\n",
        "    num_batches = 50\n",
        "    input_ids = single_batch[\"input_ids\"].numpy()\n",
        "    attention_mask = single_batch[\"attention_mask\"].numpy()\n",
        "\n",
        "    ort_session.run(None, {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask\n",
        "    })\n",
        "\n",
        "    batch_times = []\n",
        "    for _ in range(num_batches):\n",
        "        start = time.time()\n",
        "        ort_session.run(None, {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask\n",
        "        })\n",
        "        batch_times.append(time.time() - start)\n",
        "\n",
        "    batch_fps = (input_ids.shape[0] * num_batches) / np.sum(batch_times)\n",
        "    print(f\"Batch Throughput: {batch_fps:.2f} FPS\")"
      ],
      "metadata": {
        "id": "6OLUNUh31QLV"
      },
      "id": "6OLUNUh31QLV",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Apply basic graph optimizations"
      ],
      "metadata": {
        "id": "489OE5kZ1khe"
      },
      "id": "489OE5kZ1khe"
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = \"models/model.onnx\"\n",
        "optimized_model_path = \"models/model_optimized.onnx\"\n",
        "\n",
        "session_options = ort.SessionOptions()\n",
        "session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n",
        "session_options.optimized_model_filepath = optimized_model_path\n",
        "\n",
        "ort_session = ort.InferenceSession(\n",
        "    onnx_model_path,\n",
        "    sess_options=session_options,\n",
        "    providers=[\"CPUExecutionProvider\"]\n",
        ")"
      ],
      "metadata": {
        "id": "sF4gNLhj0nku"
      },
      "id": "sF4gNLhj0nku",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = \"models/model_optimized.onnx\"\n",
        "ort_session = ort.InferenceSession(onnx_model_path, providers=[\"CPUExecutionProvider\"])\n",
        "benchmark_session(ort_session)"
      ],
      "metadata": {
        "id": "aHbK_trg1wzC",
        "outputId": "06c47ab2-67cf-4bcb-d60e-f35cb46e95d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "aHbK_trg1wzC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution provider: ['CPUExecutionProvider']\n",
            "Accuracy (0.01% sampled): 96.09% (123/128 correct)\n",
            "Inference Latency (single sample, median): 24.31 ms\n",
            "Inference Latency (single sample, 95th percentile): 25.66 ms\n",
            "Inference Latency (single sample, 99th percentile): 32.61 ms\n",
            "Inference Throughput (single sample): 40.47 FPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dynamic quantization"
      ],
      "metadata": {
        "id": "cIj7mL9J15ry"
      },
      "id": "cIj7mL9J15ry"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IfBccYP017gd"
      },
      "id": "IfBccYP017gd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a8b4bc5064ca44e5b574d8c0eb815258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b1d131a8a924326a24a7779e37ab2c0",
              "IPY_MODEL_552808e00445482fa25dd65ff6195466",
              "IPY_MODEL_d91cef8296cb40028c1d65d4287dbe48"
            ],
            "layout": "IPY_MODEL_48cb8e36b85948f4ab4ea3058d7dd83c"
          }
        },
        "9b1d131a8a924326a24a7779e37ab2c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3059fd8ffac4bad89d43b113f06e215",
            "placeholder": "​",
            "style": "IPY_MODEL_4791f89c223b4ddc8cc1f26a981548ec",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "552808e00445482fa25dd65ff6195466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d46d264e72446fa4729886ad7a88eb",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc11b20cb2a8495cac4277a6c926648f",
            "value": 48
          }
        },
        "d91cef8296cb40028c1d65d4287dbe48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db54ed068fcf464ebcf87b70fe1fe4d6",
            "placeholder": "​",
            "style": "IPY_MODEL_6a909ffe347a4802b0a9fc06c4e2ac48",
            "value": " 48.0/48.0 [00:00&lt;00:00, 5.46kB/s]"
          }
        },
        "48cb8e36b85948f4ab4ea3058d7dd83c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3059fd8ffac4bad89d43b113f06e215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4791f89c223b4ddc8cc1f26a981548ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57d46d264e72446fa4729886ad7a88eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc11b20cb2a8495cac4277a6c926648f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db54ed068fcf464ebcf87b70fe1fe4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a909ffe347a4802b0a9fc06c4e2ac48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b21567ffe254d18be83e9d6f7b3daf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba91cbd81a2644018e57f5f20579a801",
              "IPY_MODEL_2b3df0119d8141e4b3056372078878c0",
              "IPY_MODEL_c2142ccef0b2416daea74ea7f8fa427b"
            ],
            "layout": "IPY_MODEL_ac6243d0c50d4bfea68c046023b187d7"
          }
        },
        "ba91cbd81a2644018e57f5f20579a801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f001922f43945aa83206f58ecd88f61",
            "placeholder": "​",
            "style": "IPY_MODEL_d7829b14f1ae4713b259ec0d65125ca6",
            "value": "vocab.txt: 100%"
          }
        },
        "2b3df0119d8141e4b3056372078878c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf96061926634408a261ec9a6179310c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75d3847c087248fe9aee44a5452333cd",
            "value": 231508
          }
        },
        "c2142ccef0b2416daea74ea7f8fa427b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f38aea8065a248a39b267e1407a1e1dc",
            "placeholder": "​",
            "style": "IPY_MODEL_6af0fc9b6b38474aa0b1e4b4db82cb8b",
            "value": " 232k/232k [00:00&lt;00:00, 1.50MB/s]"
          }
        },
        "ac6243d0c50d4bfea68c046023b187d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f001922f43945aa83206f58ecd88f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7829b14f1ae4713b259ec0d65125ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf96061926634408a261ec9a6179310c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d3847c087248fe9aee44a5452333cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f38aea8065a248a39b267e1407a1e1dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af0fc9b6b38474aa0b1e4b4db82cb8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d840043e798e4b6584413a175b39b104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6c4e42f38f03418c8f4edcf71aeb6d1c",
              "IPY_MODEL_cc6de4e7c0d046f8b562968e859a5386",
              "IPY_MODEL_b2c66d5a942b439d959cc7ee86fafd14"
            ],
            "layout": "IPY_MODEL_3bc1be7acef54af0baefc6ce2bd71198"
          }
        },
        "6c4e42f38f03418c8f4edcf71aeb6d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6c0dee16694cd794158530feaa7645",
            "placeholder": "​",
            "style": "IPY_MODEL_bf020a77ece94878ab91527a7cb5c3e7",
            "value": "tokenizer.json: 100%"
          }
        },
        "cc6de4e7c0d046f8b562968e859a5386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_257862580509429db0a597daa1c509d5",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41bf3f1452264fedaf4acc619d15aa56",
            "value": 466062
          }
        },
        "b2c66d5a942b439d959cc7ee86fafd14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f00460674c014065bd851c335f7affdf",
            "placeholder": "​",
            "style": "IPY_MODEL_9506f5f3307c41d78def18a4e99f3d3f",
            "value": " 466k/466k [00:00&lt;00:00, 8.11MB/s]"
          }
        },
        "3bc1be7acef54af0baefc6ce2bd71198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f6c0dee16694cd794158530feaa7645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf020a77ece94878ab91527a7cb5c3e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "257862580509429db0a597daa1c509d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41bf3f1452264fedaf4acc619d15aa56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f00460674c014065bd851c335f7affdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9506f5f3307c41d78def18a4e99f3d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e96ae2ef1fc41c087985fc44db1f03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51310bb0ae2b47ab936b913479d0ab79",
              "IPY_MODEL_2f5239aa309a4c42a6d169626b9f5606",
              "IPY_MODEL_5789692fe5e748eba6d779b8e1c096db"
            ],
            "layout": "IPY_MODEL_d446770c77104531b801feee3a0180df"
          }
        },
        "51310bb0ae2b47ab936b913479d0ab79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14e20ddd683a41ac807e86d21233958c",
            "placeholder": "​",
            "style": "IPY_MODEL_7ea2bde798bb4e61b2cb7707154767ba",
            "value": "config.json: 100%"
          }
        },
        "2f5239aa309a4c42a6d169626b9f5606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9499cbc8f941dbb338ed41d850d759",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4a86af5669b4fee947da12780c31f57",
            "value": 483
          }
        },
        "5789692fe5e748eba6d779b8e1c096db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d73701e68764559bcba8a76cbd50ded",
            "placeholder": "​",
            "style": "IPY_MODEL_9b48d0f1174047648a6255f57f8fa611",
            "value": " 483/483 [00:00&lt;00:00, 57.7kB/s]"
          }
        },
        "d446770c77104531b801feee3a0180df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14e20ddd683a41ac807e86d21233958c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea2bde798bb4e61b2cb7707154767ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b9499cbc8f941dbb338ed41d850d759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a86af5669b4fee947da12780c31f57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d73701e68764559bcba8a76cbd50ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b48d0f1174047648a6255f57f8fa611": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9092286bd814786b36f10ae258cb21e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f05f093f70d4f82958ea95943868ea2",
              "IPY_MODEL_03e784427660462eba19a57b98183b3b",
              "IPY_MODEL_38301cc877324982be7ad8949bb3cbbb"
            ],
            "layout": "IPY_MODEL_083c6078f1ea4852a7591308040982d0"
          }
        },
        "4f05f093f70d4f82958ea95943868ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_498d5115765141b8a25a1d8555c8f7cb",
            "placeholder": "​",
            "style": "IPY_MODEL_4b09b712f06442a8920c416c4c9a2e6a",
            "value": "model.safetensors: 100%"
          }
        },
        "03e784427660462eba19a57b98183b3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_641c615cc23e46a0989b7226eece3662",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee7a9c035a9142178b9c2a16bdf29110",
            "value": 267954768
          }
        },
        "38301cc877324982be7ad8949bb3cbbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a543b2148cc34d2b9c54fbe5d012e28a",
            "placeholder": "​",
            "style": "IPY_MODEL_883c7452c491455589f9182b78ca4d28",
            "value": " 268M/268M [00:01&lt;00:00, 252MB/s]"
          }
        },
        "083c6078f1ea4852a7591308040982d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "498d5115765141b8a25a1d8555c8f7cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b09b712f06442a8920c416c4c9a2e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "641c615cc23e46a0989b7226eece3662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee7a9c035a9142178b9c2a16bdf29110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a543b2148cc34d2b9c54fbe5d012e28a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "883c7452c491455589f9182b78ca4d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}